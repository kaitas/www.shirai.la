<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>iwadate &#8211; iwalog</title>
	<atom:link href="http://new.shirai.la/iwadate/?feed=rss2&#038;author=9" rel="self" type="application/rss+xml" />
	<link>http://new.shirai.la/iwadate</link>
	<description>岩楯のブログだよ</description>
	<lastBuildDate>
	Wed, 28 Feb 2018 23:24:52 +0000	</lastBuildDate>
	<language>ja</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.1.6</generator>
	<item>
		<title>2011/08/24　映像情報メディア学会年次大会メモ</title>
		<link>http://new.shirai.la/iwadate/?p=103</link>
				<comments>http://new.shirai.la/iwadate/?p=103#respond</comments>
				<pubDate>Wed, 16 Jan 2013 09:18:38 +0000</pubDate>
		<dc:creator><![CDATA[iwadate]]></dc:creator>
				<category><![CDATA[研究室]]></category>

		<guid isPermaLink="false">http://new.shirai.la/iwadate/?p=103</guid>
				<description><![CDATA[シンポジウム1『体感、インタラクティブメディア』 8月24日（水） 8号館 4F &#8230; <a href="https://new.shirai.la/iwadate/?p=103">続きを読む <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p><b>シンポジウム1『体感、インタラクティブメディア』</b></p>
<p align="left"><b>8</b><b>月24日（水） 8号館 4F 第1会場 09:30～12:30</b></p>
<p align="left">体全身をセンサとするゲームの出現、３D映像と触覚を併用したメディアの進展に見られるように、身体を利用するメディアの発展は昨今著しい。そこで、本イベントでは、話題の体感、インタラクティブメディアに関連する技術について多方面から講演をいただき、将来のメディアの方向性を探る。</p>
<p align="left">※S1-3とS1-5は順番が入れ替わっております．</p>
<table border="1" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td valign="top" width="120">
<p align="left"><b> </b></p>
</td>
<td valign="top">
<p align="left"><b>司会：佐藤 誠（東工大）</b></p>
</td>
</tr>
<tr>
<td valign="top">
<p align="left"><b>35</b><b>分</b></p>
</td>
<td valign="top">
<p align="left">[S1-1] VR世界と体感インタラクション<br />
佐藤 誠（東工大）</p>
</td>
</tr>
<tr>
<td valign="top">
<p align="left"><b>35</b><b>分</b></p>
</td>
<td valign="top">
<p align="left">[S1-2] 実世界指向ゲームインタラクション技術の歴史、フィロソフィ、そして近未来<br />
白井暁彦（神奈川工科大）</p>
</td>
</tr>
<tr>
<td valign="top">
<p align="left"><b>35</b><b>分</b></p>
</td>
<td valign="top">
<p align="left">[S1-5] 触覚エンタテインメント<br />
梶本裕之（電通大）</p>
</td>
</tr>
<tr>
<td valign="top">
<p align="left"><b>35</b><b>分</b></p>
</td>
<td valign="top">
<p align="left">[S1-4] 触覚メディアの可能性と課題<br />
篠田裕之（東大）</p>
</td>
</tr>
<tr>
<td valign="top">
<p align="left"><b>35</b><b>分</b></p>
</td>
<td valign="top">
<p align="left">[S1-3] 表現のためのインタラクティブ技術<br />
稲見昌彦（慶大）</p>
</td>
</tr>
</tbody>
</table>
<h3>第1部門 メディア処理1</h3>
<p>8月24日（水） 8号館 4F 第2会場 09:00～11:50</p>
<p><strong>座長：宮崎 勝（NHK）、望月貴裕（NHK）</strong></p>
<p><b>1</b><b>－4 博物館来館者の疎な位置からの経路推定<br />
</b><b>■</b><b> </b><b>河村 聡一郎・山崎俊彦・相澤清晴（東大）</b></p>
<p><b>1</b><b>－5 主成分分析を用いた車のフロントフェースの特徴解析と車似顔絵の生成<br />
</b><b>■</b><b> </b><b>ホウケン・金子正秀（電通大）</b></p>
<h3>第4部門 映像表現&amp;立体映像技術</h3>
<p>8月24日（水） 8号館 4F 第3会場 13:00～16:30</p>
<p><strong>座長：奥田　誠（NHK），平山雄三（東芝）</strong></p>
<p><b>4</b><b>－1 電荷排出変調構造を用いたTOF距離画像センサ<br />
</b><b>■</b><b> </b><b>韓 相萬・安富啓太・川人祥二（静岡大）</b></p>
<h3>第5部門 情報ディスプレイ</h3>
<p>8月24日（水） 8号館 3F 第4会場 09:00～12:35</p>
<p><strong>座長：石井啓二（NHK），藤掛英夫（NHK）</strong></p>
<p><b>5</b><b>－6 交通情報システム向けデジタルサイネージシステムにおけるカメラ連携表示コンテンツ制御<br />
</b><b>■</b><b> </b><b>椿 泰範・宮原浩司・吉田 浩・米沢みどり（三菱電機）、高梨郁子（三菱電機インフォメーションシステムズ）</b></p>
<p>メモ</p>
<p>ネットワーク型デジタルサイネージシステム<br />
カメラ付きの構成が増えている。ディスプレイ前を撮影して、性別年代を認識してオススメ商品を表示するものなどもある<br />
カメラ映像によって他の地点のディスプレイのコンテンツを制御<br />
カメラから混雑情報を取得（画像処理）、配信管理サーバに送って表示地点に配信する。混雑状態によって表示コンテンツを切り替える。画像処理は背景差分<br />
表示制御端末、ディスプレイ、カメラでひとユニット<br />
中部国際空港で実証実験。保安検査場の混雑情報を他の地点に表示させたいという背景。空港では基本的な人の流れがある程度決まっている<br />
52インチ（1929×1080）のディスプレイをタイル状に並べて配置<br />
コンテンツ内容：静止画、アニメーション、時計など</p>
<p>結果。混雑状態が実際の場所に着くまでに変化していたケースもあった。アンケート結果から設置が望まれている。</p>
<p><b>5</b><b>－7 交通向けデジタルサイネージシステム<br />
</b><b>■</b><b> </b><b>吉田 浩・宮原浩二・椿 泰範・米沢 みどり（三菱電機）、高梨郁子（三菱電機インフォメーションシステムズ）</b></p>
<p><b>メモ</b></p>
<p>旅客目線で考えた情報を提示するデジタルサイネージ。検査場混雑情報（知りたい情報）、お土産情報（気になる情報）等。空港に観光目的できている人もいるのでその人達にも向けた情報<br />
トレインビジョン＝デジタルサイネージ<br />
最新情報への更新遅延は数秒から30秒程度。見た目5秒くらい<br />
顔数（60分当たりの検出）、通過人数、混雑度をはかっている。<br />
視認率　顔数/人数<br />
画面の文字が読める条件下で一定時間の滞留をカウント<br />
視認の指標は今まだ定かではない。<br />
1セット90秒。三面広告19秒→それぞれの画面30秒→のスパン<br />
サイネージに気付いたきっかけは？　フライト情報。なんとなく。動きが目立っていた等<br />
休日の方が視認率は高くなる。滞留場所ではないがサイネージがあったために滞留がみられた</p>
<p><b> </b></p>
<p><b>5</b><b>－9 背面投射用音響透過スクリーンの検討<br />
</b><b>■</b><b> </b><b>濱崎公男・金澤 勝（NHK）、原田良三・国分秀樹（NHK-ES）</b></p>
<p>スクリーンに穴があいている（孔子）。それを重ね合わせたものを作成。無孔の、孔子のミルフィーユ<br />
有孔スクリーン4層の場合でもスクリーンなしとほとんど変わらない状態まで音が透過する。開孔10%の場合<br />
一般に用いている拡散による背面投射用スクリーンでは穴をあけると映像が暗くなるから使えない。なので穴をあけたレンズシートを使う背面投射を検討<br />
レンズシート1枚では映像投射スクリｰンとしては使用できないが3枚以上重ねた場合であれば使用が可能。</p>
<h3>第6部門 画像処理1</h3>
<p>8月24日（水） 8号館 3F 第4会場 13:00～16:50</p>
<p><strong>座長：井上光平（九大）、河合吉彦（NHK）</strong></p>
<p><b>■</b><b> 6</b><b>－2 距離カメラを用いた人物の行動検出法の検討<br />
</b><b>■</b><b> </b><b>浜木翔太・中野愼夫・西原 功（富山県立大）</b></p>
<p>病院内で、徘徊等のあれがあり今は監視カメラを使っている。<br />
人物の位置の変化、形状の変化をとれれば行動検出ができるのではないか。建物内の照明状態に左右されない距離カメラを使用する。オプテックス社ZC-1070U<br />
物体検出→人物の軌跡検出<br />
検出したものから隣り合う画素の変化量をみて、変化が小さいものを繋げて同一物体として認識する</p>
<p>距離取得回数　30回/秒</p>
]]></content:encoded>
							<wfw:commentRss>http://new.shirai.la/iwadate/?feed=rss2&#038;p=103</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>HCGまとめ</title>
		<link>http://new.shirai.la/iwadate/?p=82</link>
				<comments>http://new.shirai.la/iwadate/?p=82#respond</comments>
				<pubDate>Fri, 14 Dec 2012 12:12:15 +0000</pubDate>
		<dc:creator><![CDATA[iwadate]]></dc:creator>
				<category><![CDATA[研究室]]></category>

		<guid isPermaLink="false">http://new.shirai.la/iwadate/?p=82</guid>
				<description><![CDATA[12/10　1日目 セッションⅢ-1：障がい者支援（会議室D） Ⅲ-1-1　「認 &#8230; <a href="https://new.shirai.la/iwadate/?p=82">続きを読む <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p><strong>12/10　1日目</strong></p>
<p><strong>セッションⅢ-1：障がい者支援（会議室D）</strong><br />
Ⅲ-1-1　<strong>「認知症の人の行動・心理症状を理解するための経験拡張行動シュミレータの実現に向けて」</strong><br />
○藤田真浩・長尾貴正（静岡大）・上野秀樹（静岡大/海上寮）・玉井　顯（敦賀温泉病院）・石川翔吾・竹林洋一（静岡大）</p>
<p>認知症の人が起こす苛々や大声、暴力等の行動には、「やれることは自分でやりたいけど<br />
うまく言葉で伝えられないからやらせてもらえない」等色々な背景があるのでそれを我々が理解できるようなものを用意する。<br />
→認知症を理解して啓発させるためのシュミレータ（理解するための情報コンテンツ）</p>
<p>どうやって<strong>BPSD</strong>（認知症に伴う徘徊や妄想・攻撃的行動・不潔行為・異食などの行動・心理症状のこと）を表現するのかが課題<br />
→子供の発達行動を利用する事で解決できるのでは？を検証</p>
<p><strong>セッションⅢ-2：コンピュータビジョン（会議室D）</strong><br />
Ⅲ-2-4　<strong>「人の視界を表示するウォークスルー」</strong><br />
○渡邉俊哉・渋沢　進（茨城大）</p>
<p>複数の全方位カメラをつかってウォークスルーを作る</p>
<p>店内での顔方向（視線）を調べる<br />
→犯罪者が犯罪行動をとるときの視点を監視者に体験させる事で犯罪の抑制を</p>
<p>顔の位置、顔の肌色領域（背景差分）で顔の方位を見る（対象者1名。動線もとれる）</p>
<p>課題<br />
・カメラから遠いと認識ができない<br />
・環境光に影響される<br />
・カメラ方向へ体が向いているとき以外での顔方向取得は微妙</p>
<p><strong>セッションⅢ-3：集団行動（会議室D）</strong><br />
Ⅲ-1-1　<strong>「集団行動解析のための歩容意図コーパス」</strong><br />
○波部　斉・木戸出正継（近畿大）・鷲見和彦（青学大）・八木康史・満上育久・梶原光平（阪大）・青木菜々美（青学大）・園部信隆（近畿大）</p>
<p>集団行動をしているときのそれぞれの人の役割<br />
→身振り手振りで分かる？</p>
<p>歩容から集団意図をよみとるのが目的。センシングについてはふれずに、まずはコーパス（コンピュータによる検索が可能になっている大量の言語データ）を作る</p>
<p>リファ：「人物動線データ群における逸脱行動人物検出及び行動パターン分類」<br />
鈴木　直彦，平澤　宏祐，田中　健一，小林　貴訓，佐藤　洋一，藤野　陽三<br />
誌名：電子情報通信学会論文誌 D  Vol.J91-D  No.6  pp.1550-1560<br />
発行日: 2008/06/01<br />
Online ISSN: 1881-0225<br />
Print ISSN: 1880-4535<br />
論文種別: 論文<br />
専門分野: パターン認識<br />
内容：画像センサ・GPS・レーザレーダなどから得られる移動体経路情報に基づいた状況理解として，各種センサから得られる人物動線データ群からの逸脱行動人物検出及び行動パターン分類を行う手法の提案を行う．提案手法では，HMM（Hidden Markov Model）を用いてモデル化した人物動線データを低次元空間上に射影し，クラスタリング及び外れ値検出に基づいて逸脱行動人物検出及び行動パターン分類を行う．また，過去に得られた人物動線データ群の検索とリアルタイム検出した人物動線データの識別を行うためのスキームも同時に提案する．実空間で得られた人物動線データ群を用いた検証を行い，提案手法により有効な結果が得られることが分かった．本論文の提案手法は，セキュリティシステム・マーケティング分析などへの応用が考えられる．</p>
<p>実験<br />
短時間の集団行動状態（未来館での展示の様子を1分程度）をビデオを使って見てみる。<br />
その後アンケートでどんな集団（家族とか）なのか？等を聞く<br />
→選択式アンケートのための選択肢を絞り込むため、最初は自由形式でのアンケート</p>
<p>役割の例<br />
・リーダー<br />
・情報収集<br />
・主人公（子供とか）<br />
・傍観者<br />
・その他</p>
<p>展示室内でどの展示を見るか決める（←ここが知りたい！）</p>
<p>軌跡と指さし方向のアクションを利用してコーパスを作る<br />
<strong>HCGシンポジウム招待講演（プラザホール）</strong><br />
<strong> 「海のこころ、森のこころ～こころの起源に迫る比較認知科学～」</strong><br />
○友永雅己　（京都大学霊長類研究所）</p>
<p>人は、色々な物の画像を散りばめた画面の中から人の顔画像だけの物は他のものよりも何故か見つけやすい（カメラ目線のひとの顔を見つけるのも簡単）</p>
<p>ではそれはチンパンジーでも同じなのか？<br />
→同じだった<br />
そしてバナナの写真も何故か見つけやすい<br />
→腹減ってたわけではなく、色のせいであると思われる</p>
<p>しかし、今度は人の顔の画像を倒立させて同じように探してみると反応が遅れる<br />
バナナの場合は倒立しても変わらないが、色を変えると同じく遅れる<br />
↓<br />
<strong>物によって見分け方を変えている！</strong></p>
<p>また、顔に似た建物等の無機物画像の場合でも（目、鼻、口がちゃんと顔見たく並んでいれば）見つけやすくなる（同様に、倒立させたり半分から切って横にずらしても分かりにくくなる）<br />
↓<br />
顔っぽい建物の画像だと横に並んだ目の位置が大切な要素になるかもしれない</p>
<p>Fat face illusion<br />
→顔を倒立させて見てみると正立と比べてスリムに見える<br />
[browser-shot url=&#8221;http://www.psy.ritsumei.ac.jp/~akitaoka/nisshin_kao2010.html&#8221;]<br />
参考</p>
<p>Jastrow illusion<br />
→縦に並べたものだと上の方がスリムに見える</p>
<p><strong>12/11　２日目</strong><br />
<strong>MVE企画セッション（プラザホール）</strong><br />
「マルチスクリーン連携技術の現状と未来」4人の登壇。タイトルはわからん<br />
1番目：苗村健氏（東京大）<br />
・ルミサイトテーブル<br />
[browser-shot url=&#8221;http://news.mynavi.jp/articles/2004/08/14/siggraph1/002.html&#8221;]</p>
<p>・MRsion Case<br />
→色々な方向から見たくなる展示</p>
<p>・Hand-rewriting<br />
→paper based なんとか<br />
[browser-shot url=&#8221;http://jp.diginfo.tv/v/12-0200-r-jp.php&#8221; width=&#8221;600&#8243;]</p>
<p>・複製でも拡張でもない画面共有（SHelective）について</p>
<p>Inter-personal Browsing<br />
web画面の共有（検索結果とか）<br />
共同でwebを使って調べ物するときとかに使う。見ててもいいよってものだけを共有<br />
→見たい情報の画面をタッチすると自分の端末にそのデータをもらえる（Ctrl+タッチ）<br />
共有のための拡張画面はiPad</p>
<p><strong>Inter-Personal Browsing:ブラウザ拡張機能による実世界指向情報共有</strong><br />
著者名:野村 浩気，橋田 朋子，苗村 健<br />
著者所属: 東京大学工学部<br />
東京大学大学院情報理工学系研究科<br />
東京大学工学部／東京大学大学院情報理工学系研究科</p>
<p>論文抄録: 本稿では，複数人で協調・分担して問題の多角的解決や創発的作業に取り組むグループワークにおいて，情報の収集・共有を円滑に行うシステムについて検討する．具体的には，グループでのウェブ検索活動に対象を絞り，private／publicという観点から効率的で円滑な情報提示を実現する手法として，ブラウザ拡張による実装と実世界指向インタラクションのデザインを行った．特に，あるユーザの検索結果を共有し，他のユーザがその情報を転送して得るための手段として，Push型とPull型の仕組みを提案し，実験を通じてその有効性を確認した．</p>
<p>雑誌名: 研究報告エンタテインメントコンピューティング（EC）<br />
巻: 2012-EC-23<br />
号: 7<br />
ページ: 1 &#8211; 6<br />
発行年: 2012-03-19</p>
<p>2番目：有安香子氏（NHK）<br />
番組のこと</p>
<p>テレビと一緒に何かをする<br />
オーディオフィンガープリント（コンテンツのバイオメトリクス. −フィンガープリント技術）<br />
ソーシャルテレビサービス<br />
teleda　vod+コミュニケーション<br />
[browser-shot url=&#8221;https://pid.nhk.or.jp/pid16/teleda2011/&#8221; width=&#8221;600&#8243;]</p>
<p>口コミ（評価コメント）や番組推薦機能で番組盛り上げたい<br />
→ドキュメンタリー、ドラマを多く見ているひとは評価コメントを残さない傾向にあることがわかった<br />
また、オススメ機能で推薦されたものより他人の評価が高い番組の方が再生回数が多い</p>
<p>3番目：瀬古俊一氏（NTT）<br />
災害のときの</p>
<p>ネットが繋がらないと情報がどことも繋がらない。<br />
↓<br />
サイネージと手元端末を連携させる事で解決させよう？<br />
→サイネージ付近に人が滞留しすぎて画面が見えずってのを解決させる<br />
使い方は平常時でもクーポン取得とかでサイネージとの連携を使わせる事で慣れさせる</p>
<p>レジリエント情報流通</p>
<p>新たにアプリとか端末とかをユーザが余分に用意しないでいいようにHTML5を使って端末とサイネージを繋げる</p>
<p>避難所間での情報共有（※ルータ、LAN内にwebサーバが存在する事が現状の条件）</p>
<p>4番目：山口德郎氏（沖電気）<br />
サイネージ連携<br />
[browser-shot url=&#8221;http://www.oki.com/jp/press/2010/05/z10024.html&#8221; width=&#8221;600&#8243;]</p>
<p>認識センサ付きの公共ディスプレイとスマフォのペアリング<br />
端末→ディスプレイの連携だとジェスチャーとか利用者に特別な行動を求める</p>
<p>嗜好に合わせたサイネージ<br />
→自分が欲しい広告を、スマフォをリモコン代わりに使って表示させるサイネージを選ぶ<br />
→選んだらその広告の更に関連情報がみられる</p>
<p>応用<br />
タイルドディスプレイ<br />
ベゼル使って画面の一つを個人的にプライベート利用する</p>
<p><strong>12/12　３日目</strong><br />
<strong>セッションⅡ-7：ユーザインタフェース（会議室A+B）</strong><br />
Ⅱ-7-3　<strong>「大型公共ディスプレイ上へのプライベート情報提示方法の検討」</strong><br />
○飯塚重善（神奈川大）・内藤　航・郷　健太郎（山梨大）</p>
<p>公共ディスプレイをインタラクティブに、プライベートに使う</p>
<p>関連研究<br />
Daniel Vogel　ディスプレイのプライベート利用<br />
<strong>「Interactive public ambient display: transitioning from implicit to explicit, public to personal interaction with multiple users」？</strong><br />
[browser-shot url=&#8221;http://dl.acm.org/citation.cfm?id=1029656&#8243; width=&#8221;600&#8243;]</p>
<p>大型公共ディスプレイで安心して情報を使える情報環境を目指す</p>
<p>想定利用シーン<br />
駅にある公共ディスプレイに携帯端末に表示してあった地図を表示させるとか<br />
スマフォをサイネージにかざす→サイネージに地図が表示される→スマフォをサイネージにかざす→スマフォにサイネージに表示したデータが返ってくる</p>
<p>実験<br />
大学のロビーにディスプレイを置いて軌跡の変化を観察する<br />
→ディスプレイ無し、ディスプレイのみ、ディスプレイ+有人での設置評価した結果、ディスプレイを置いただけで人の動線が変化し、無し～有人に状態をうつすにつれてディスプレイに近づく軌跡が増えた。なお、軌跡の評価は、ビデオ内特定領域に50cm四方のグリッドを想定してどこのブロックに入ってるかを視聴で調査。</p>
<p>公共ディスプレイで表示可能なプライバシーレベルをユーザが予め設定しておいてそれに応じたものだけを表示できるようにしたらいいのではないかという提案<br />
リファ：「」<br />
○飯塚　他　2007</p>
<p>危険度提示システム</p>
<p>自分の発表について<br />
UbiCodeへの質問<br />
Q．裏にQRコードじゃなくて別のコンテンツを使ったら？<br />
Q．どうやって裏に広告の裏にコードがある事を知るの？<br />
Q．サイネージのどこにコードがあるのかを体験者は迷わなかった？<br />
Q．？</p>
<p>意見：フィルタを携帯ストラップにつけることでUbiCodeに使えたり、携帯カメラで逆光のとき撮影するのに使ったりするのもいいかもしれないですね。</p>
]]></content:encoded>
							<wfw:commentRss>http://new.shirai.la/iwadate/?feed=rss2&#038;p=82</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>HCG</title>
		<link>http://new.shirai.la/iwadate/?p=71</link>
				<comments>http://new.shirai.la/iwadate/?p=71#comments</comments>
				<pubDate>Sat, 01 Dec 2012 08:33:37 +0000</pubDate>
		<dc:creator><![CDATA[iwadate]]></dc:creator>
				<category><![CDATA[研究室]]></category>

		<guid isPermaLink="false">http://new.shirai.la/iwadate/?p=71</guid>
				<description><![CDATA[自分とこのプログラム セッションIII-2：コンピュータビジョン（12:45-1 &#8230; <a href="https://new.shirai.la/iwadate/?p=71">続きを読む <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<p><a href="https://new.shirai.la/iwadate/files/2012/12/customLogo.png"><img src="http://new.shirai.la/iwadate/files/2012/12/customLogo.png" alt="" width="799" height="274" class="aligncenter size-full wp-image-76" srcset="http://new.shirai.la/iwadate/files/2012/12/customLogo.png 799w, http://new.shirai.la/iwadate/files/2012/12/customLogo-300x102.png 300w, http://new.shirai.la/iwadate/files/2012/12/customLogo-500x171.png 500w" sizes="(max-width: 799px) 100vw, 799px" /></a></p>
<p>自分とこのプログラム<br />
<strong>セッションIII-2：コンピュータビジョン（12:45-14:25＠会場III）</strong><br />
(III-2-1) 人物が存在し得る部分空間の多重スリット表現による可視化<br />
○中野一成・亀田能成・大田友一（筑波大）<br />
<strong>(III-2-2) 多重化隠蔽タグ技術UbiCodeを使ったデジタルサイネージのインタラクティブ化によるコミュニケーション支援<br />
</strong>○<span style="text-decoration: underline"><strong>岩楯翔仁</strong></span>・小出雄空明・大塚真吾・白井暁彦（神奈川工科大）<br />
(III-2-3) 周辺環境を考慮したカラー手袋による手指形状の認識実験とその評価<br />
○菅谷隆浩・加藤正樹・鈴木孝幸・西村広光・田中　博（神奈川工科大）<br />
(III-2-4) 人の視界を表示するウォークスルーシステム<br />
○渡邉俊哉・渋沢　進（茨城大）</p>
<p>気になるプログラム<br />
<strong>12月10日（月）</strong><br />
<strong>セッションIII-2：コンピュータビジョン（12:45-14:25＠会場III）</strong><br />
(III-2-1) 人物が存在し得る部分空間の多重スリット表現による可視化<br />
○中野一成・亀田能成・大田友一（筑波大）</p>
<p><strong>セッションIII-3：集団行動（14:35-15:50＠会場III）</strong><br />
(III-3-1) 集団行動解析のための歩容意図コーパス<br />
○波部　斉・木戸出正継（近畿大）・鷲見和彦（青学大）・八木康史・満上育久・梶原光平（阪大）・青木菜々美（青学大）・園部信隆（近畿大）<br />
(III-3-3) 会話ロボットに対する人の興味の持続　～ 人工物演劇プロジェクトへの準備として ～<br />
○安藤敏彦・松山　薫・鈴木静香（仙台高専）</p>
<p><strong>招待講演<br />
海のこころ、森のこころ ─ こころの起源に迫る比較認知科学 ─ 　　京都大学霊長類研究所　友永雅己氏　12月10日（月）17:00〜</strong><br />
これまで，主としてチンパンジーなどの大型類人猿を対象として，彼らのこころの機能に関する実験的研究を進めてきた．私たちの目標は，「ヒトのこころはどのようにして進化してきたのか．そしてそれはなぜか」という壮大な問いに対して，現生種間の認知機能の実証的研究と種間比較を通して答えようとするものである．このような研究領域を私たちは「比較認知科学」と呼んでいる．さらに，最近では，イルカなどの小型鯨類を対象とした研究にも着手し始めた．私たち人間の知性は森の中で生まれ育まれてきた．それに対し，再び海に戻ったイルカたちのこころは，森とは全く異なる環境に適応した結果，今ここに存在している．森のこころと海のこころを適切に比較検討することによって，こころの進化における2つの側面，すなわち系統発生的制約と環境適応の要因がより明確になるものと期待している．本発表では，チンパンジーとイルカを対象とした最近の研究を紹介しながら，この問題について考えてみたい．</p>
<p><strong>ＨＣＳ研究会（ヒューマンコミュニケーション基礎第一種研究会）企画<br />
コミュニケーションの進化と未来：霊長類からジェミノイドまで　　12月10日（月）17:00～19:00</strong><br />
ジェミノイド研究の小川浩平氏（大阪大学），コミュニケーションロボットを用いたユニークな取り組みで知られる高橋英之氏（玉川大学）の2名が人―モノのコミュニケーションに関する研究を紹介します．さらにディスカッサントとして，京都大学霊長類研究所の友永雅己氏，および心理臨床面接や作業療法におけるコミュニケーション研究を行っている長岡千賀氏（京都大学）が参加し，情報コミュニケーションシステムの将来像を議論します．</p>
<p><strong>12月11日（火）</strong><br />
<strong>セッションI-4：ヒューマンセンシング（9:10-10:50＠会場I）</strong><br />
(I-4-1) 慣性センサ内蔵端末と超音波センサを用いた屋内測位プラットフォームの基本検討<br />
○秋山征己・白井宏幸・屋良朝克・鷹野孝典・五百蔵重典・田中　博（神奈川工科大）<br />
(I-4-2) 筋電位計測とkinectセンサーによる三次元姿勢計測を用いたリハビリ支援システムの設計<br />
○朝倉　僚（京大）・宮坂淳介（京大医学部附属病院）・近藤一晃・中村裕一（京大）・秋田純一（金沢大）・戸田真志（熊本大）・櫻沢　繁（公立はこだて未来大）<br />
(I-4-4) イメージセンサを用いたワイヤ式三次元位置計測機構の精度改善に関する一検討<br />
村山　淳・○和久井祐太（東京理科大）・平田幸広（諏訪東京理科大）・佐藤　誠（東工大）・原田哲也（東京理科大）</p>
<p><strong>セッションII-4：先進的インタラクション（9:10-10:50＠会場II）</strong><br />
(II-4-1) 赤外線画像認識によりユーザ位置を識別するテーブルトップシステム<br />
○須藤翔太・渋沢　進（茨城大）</p>
<p><strong>セッションI-5：距離画像処理（11:00-12:15＠会場I）</strong><br />
(I-5-1) 距離画像に基づく表情表出時の動態解析<br />
○伊勢崎隆司・ジャヤティラカ ドゥシャンタ（筑波大）・鈴木健嗣（筑波大/JST）<br />
(I-5-2) ジェスチャ認識のためのRGB-Dカメラを用いた局所時空間特徴の比較評価<br />
○福岡龍大・川本一彦・堀内麻由・岡本一志（千葉大）<br />
(I-5-3) 距離画像を用いた動きのある指文字の非接触認識手法の検討<br />
○三宅太一・若月大輔・内藤一郎（筑波技大）</p>
<p><strong>セッションIII-5：Webとデザイン（11:00-12:15＠会場III）</strong><br />
(III-5-1) WANTSを登録する目的志向型ライフログの提案　～ 食べ物をはじめとするインタフェース ～<br />
○陳　奕親・村瀬結衣・杉浦一徳（慶大）<br />
(III-5-2) 課題提出を支援するリマインダの開発<br />
○谷村　祐・西田滉季・納富一宏（神奈川工科大）<br />
(III-5-3) ウェブアクセシビリティの配慮度合いに関連するデザイン方法の検討<br />
○渡辺昌洋・橋本　遼・森田敬樹・浅野陽子（NTT）</p>
<p><strong>ＭＶＥ研究会（マルチメディア・仮想環境基礎第一種研究会） 企画</strong><br />
マルチスクリーン連携技術の現状と未来　　12月11日（火）13:20～15:00<br />
スマートフォン，タブレット，スマートテレビ，デジタルサイネージ等，我々の生活空間にはスクリーンを備えた端末が多数普及しています．この現状を踏まえて，マルチスクリーン連携技術の現状と未来を議論します．（苗村健氏（東京大），有安香子氏（NHK），瀬古俊一氏（NTT），山口德郎氏（沖電気）らの講演を予定）</p>
<p><strong>インタラクティヴ発表（15:50-17:40＠ホワイエ）</strong><br />
(IV-1-4) アノテーションされた会話映像を用いた人の振舞いとコミュニケーション機能の分析<br />
○徳永弘子・武川直樹・木村　敦・湯浅将英（東京電機大）<br />
(I-7-3) 二者間の行動の一致性と時間差に基づく外部観察者の共感解釈の分析<br />
○熊野史朗・大塚和弘・松田昌史・大和淳司（NTT）<br />
(I-7-5) ポスターセッションの分析のための不特定複数人物の頭部形状と姿勢のオンライン自動推定<br />
○吉本廣雅・中村裕一（京大）<br />
(III-7-5) かわいい人工物の系統的研究（第14報）　～ かわいい触感に関する触素材を用いた基礎的検討 ～<br />
○大倉典子・小松　剛・大澤俊太（芝浦工大）・坂本真樹（電通大）<br />
(IV-2-11) タブレットPCを用いた聴覚障がい者・健聴者間コミュニケーション支援システムの開発<br />
○澤田由貴子・木村　勉（豊田高専）・神田和幸（中京大）<br />
(IV-2-12) 奥行き情報が視覚的注意に与える影響　～ オブジェクト置き換えマスキング実験を用いて ～<br />
○井ノ上桃子・木原　健（鹿児島大）・島村　潤・谷口行信（NTT）・大塚作一（鹿児島大）<br />
(IV-2-13) 奥行き情報が視覚的注意に与える影響　～ 高速逐次視覚呈示(RSVP)課題を用いて ～<br />
○坂元里菜・木原　健（鹿児島大）・島村　潤・谷口行信（NTT）・大塚作一（鹿児島大）<br />
(IV-2-16) Twitterを用いたスポーツ試合中のイベント検出に関する検討<br />
○富田大志（名大）・道満恵介（中京大）・井手一郎・出口大輔・村瀬　洋（名大）<br />
(I-4-2) 筋電位計測とkinectセンサーによる三次元姿勢計測を用いたリハビリ支援システムの設計<br />
○朝倉　僚（京大）・宮坂淳介（京大医学部附属病院）・近藤一晃・中村裕一（京大）・秋田純一（金沢大）・戸田真志（熊本大）・櫻沢　繁（公立はこだて未来大）<br />
(II-1-1) 共同注視状況における複数人物頭部カメラの位置姿勢推定<br />
○高瀬恵三郎・近藤一晃・小泉敬寛・中村裕一（京大）<br />
(II-1-2) コンピュータからのほめ言葉がユーザーの感情と行動に与える効果<br />
○三浦郷史・入戸野　宏（広島大）<br />
(II-1-3) ゲーミフィケーションを用いた対話エージェントのための学習データ獲得<br />
○岩田直之（名大）・鳥海不二夫（東大）・平山高嗣・榎堀　優（名大）・稲葉通将（広島市大）・間瀬健二（名大）<br />
(II-6-2) 背景音のテンポが作業ペースに与える影響　～ 音の密度と拍の知覚の交互作用効果 ～<br />
○栗林龍馬・入戸野　宏（広島大）<br />
(III-2-1) 人物が存在し得る部分空間の多重スリット表現による可視化<br />
○中野一成・亀田能成・大田友一（筑波大）</p>
<p><strong>ＣＥＡ研究会（食メディア第二種研究会）企画</strong><br />
うま味の科学－おいしく食べて，健康づくり　　味の素株式会社大阪支社　佐伯俊則氏　12月11日（火）17:40〜18:30<br />
日本で生まれた「うま味」の科学について，味の素株式会社の佐伯俊則氏から，わかりやすく解説をしていただきます．具体的には，五感で味わうおいしさの仕組み，５つの基本味，うま味の働き，うま味の相乗効果，うま味で増す味と風味（おいしさの官能評価）を明らかにしていきます．体調によって，うま味は影響を受けるなどの最新の研究も含めて，おいしさを演出する重要な要素である「うま味」について，議論ができればと思います．うま味成分を組み合わせて，うま味を感じる味覚の実験（テイスティング）も行いますので，是非，うま味の相乗効果を，ご自身の舌で感じてみてください．</p>
<p><strong>12月12日（水）</strong><br />
<strong>セッションI-7：ヒューマンコミュニケーション（9:30-12:00＠会場I）</strong><br />
(I-7-1) 広汎性発達障害児・者の意志受容を支援するコミュニケーションエイド<br />
○廣冨哲也・稲村　駿・田中教子（島根大）<br />
(I-7-3) 二者間の行動の一致性と時間差に基づく外部観察者の共感解釈の分析<br />
○熊野史朗・大塚和弘・松田昌史・大和淳司（NTT）<br />
(I-7-5) ポスターセッションの分析のための不特定複数人物の頭部形状と姿勢のオンライン自動推定<br />
○吉本廣雅・中村裕一（京大）<br />
(I-7-6) 対面コミュニケーションが新奇食物受容に及ぼす効果<br />
○木村　敦（東京電機大）・酒造正樹（神奈川大）・武川直樹・佐々木寛紀（東京電機大）・和田有史（(独)農研機構）</p>
<p><strong>セッションII-7：ユーザインタフェース（9:30-12:00＠会場II）</strong><br />
(II-7-2) SF映画からの近未来UIに関する考察とその効果<br />
○飯尾　淳（三菱総研）・飯塚重善（神奈川大）・松原幸行（キヤノン）<br />
(II-7-3) 大型公共ディスプレイ上へのプライベート情報提示方法の検討<br />
○飯塚重善（神奈川大）・内藤　航・郷　健太郎（山梨大）</p>
<p><strong>セッションIII-7：感性（9:30-12:00＠会場III）</strong><br />
(III-7-5) かわいい人工物の系統的研究（第14報）　～ かわいい触感に関する触素材を用いた基礎的検討 ～<br />
○大倉典子・小松　剛・大澤俊太（芝浦工大）・坂本真樹（電通大）</p>
<p><strong>ＣＭＬ研究会（未来世代から見たコミュニケーション科学の魅力と学習意欲向上第三種研究会）企画</strong><br />
未来世代に学ぶ　－被災地の高校生との交流を通じて学んだこと，それを学会の未来につなぐ　　12月12日（水）13:00～14:30<br />
「未来世代からみたコミュニケーション科学の魅力と学習意欲の向上」第３種研究会は，２０１１年４月に発足し，その最初の活動は，被災地の高校生を支援しながら，彼ら彼女たちが経験し学んだことをいかに未来につなげるかが中心になりました． そこでいったい何が見えてきたのでしょうか．それを電子情報通信分野の将来，そしてこれからの学会へつなげるために，私たちは何をすべきなのでしょうか．そもそも私たちがコミュニケーションするのはなぜなのでしょうか．このパネルでは，それを一緒に考えたいと思います．</p>
]]></content:encoded>
							<wfw:commentRss>http://new.shirai.la/iwadate/?feed=rss2&#038;p=71</wfw:commentRss>
		<slash:comments>2</slash:comments>
							</item>
		<item>
		<title>社会知デザイン</title>
		<link>http://new.shirai.la/iwadate/?p=55</link>
				<comments>http://new.shirai.la/iwadate/?p=55#respond</comments>
				<pubDate>Thu, 15 Nov 2012 09:56:26 +0000</pubDate>
		<dc:creator><![CDATA[iwadate]]></dc:creator>
				<category><![CDATA[研究室]]></category>
		<category><![CDATA[読書]]></category>

		<guid isPermaLink="false">http://new.shirai.la/iwadate/?p=55</guid>
				<description><![CDATA[読んでて参考になりそうな事の書き連ね 2章ミクロレベルの社会知：コミュニケーショ &#8230; <a href="https://new.shirai.la/iwadate/?p=55">続きを読む <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=4274207218&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>
<p>読んでて参考になりそうな事の書き連ね</p>
<p><strong>2章ミクロレベルの社会知：コミュニケーションの中のすばやいインタラクション</strong>（pp11~）<br />
ヴァーガスは、非言語的なコミュニケーションに用いられるメディアを、<strong>人体</strong>（性別・年齢・体格・皮膚の色等人間がそれぞれ持ち合わせている身体的特徴）、<strong>動作</strong>（顔の表情、身振りと胴体・頭・脚・足・腕・手の諸動作、立つ・座る・動く・静止をしているときの姿勢）、<strong>目</strong>（アイコンタクトや目つき）、<strong>周辺言語</strong>（声の調子・強弱・テンポ・声量等の韻律）、<strong>沈黙</strong>（話の途切れや無視するといった態度など）、<strong>身体接触</strong>（相手に触ること、ほほえみ・うなずき・アイコンタクトなどによる触覚的刺激の代用）、<strong>対人的空間</strong>（コミュニケーションに使用する空間）、<strong>時間</strong>（割り込みのタイミングや遅刻や生体的な時間など）、<strong>色彩</strong>（壁や衣服の色）の9つに分類している。<br />
Vargus,M.F.：Louder Than Words &#8212; An Introduction to Nonverbal Communication &#8211;, Iowa State University Press, 1986（邦訳：マジョリー・F・ヴァーガス著、石丸正訳：非言語コミュニケーション、新潮選書、1987）<br />
<iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=4106003341&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe></p>
<p><strong>2.1.2 普段よく使う基本的なコミュニケーション原理</strong>（pp13~）<br />
日常的な会話における対人コミュニケーションでは、コミュニケーション内容の<strong>65%</strong>が、<strong>話ぶりやジェステャといった非言語的なメディア</strong>によって伝えられ、<strong>言語的なメディアで伝えられるメッセージ量の倍近い</strong>という。<br />
表情行動の中に人間が生得的に有するとされる、<strong>悲しみ（sadness）</strong>、<strong>怒り（anger）</strong>、<strong>嫌悪（disgust）</strong>、<strong>恐怖（fear）</strong>、<strong>興味（interest）</strong>、<strong>驚き（surprise）</strong>、<strong>喜び（happiness）</strong>という7つの基本感情があり、これらの頭文字を取って<strong>SADFISH</strong>と称される。</p>
<p>ジェスチャ：身体動作によるメッセージの表現。エクマンとフリーセンは身体動作を<strong>エンブレム（emblem）</strong>、<strong>例示子（illustrator）</strong>、<strong>適応子（adaptor）</strong>、<strong>調整子（regulator）</strong>、<strong>感情表示（affect display）</strong>に分類している。<br />
<iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=4762824909&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe><iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=4469163422&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe></p>
<p>ポスチャ：<strong>肩の上がり下がり</strong>、<strong>頭の向き</strong>、<strong>体の角度</strong>、<strong>背筋の張り方</strong>といった<strong>ポスチャ</strong>（姿勢）も様々な感情的メッセージを伝える。受容的か排他的かは体の向きなどによって第三者の参加を受け入れようとしているか否かを示す。面と向かったインタラクションは、連続的に相手をモニタでき、より形式的で業務的な関係であることを示唆。平行した向きは中立的あるいは活動的でない相互関係を示唆。また、ポスチャの一致は同意、対等、相互に好感を抱いていることを示唆。逆に不一致は、地位の不均衡があることを示唆。通常は地位の高い方は、リラックスし、相手の方を向かず、反り返ったような姿勢をとり、非対称な手足のポジションを示す。逆に地位の低い方は、改まったポスチャを示し、相手の方を向き、前傾姿勢であり、筋肉は緊張し、直立した脊椎を維持する。</p>
<p>空間：エドワード・ホールが提唱したプロセミックスでは、社会生活における距離の取り方が、<strong>密接距離</strong>、<strong>個体距離</strong>、<strong>社会距離</strong>、<strong>公衆距離</strong>の4つに類別されることを示している（＝パーソナルスペース）。<br />
<iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=4622004631&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe></p>
<p>目標指向的な非言語行動が起きるのは、面接会場での会話のように行動者が他人から評価されるという圧力にさらされている場合、拒否・嫌悪・承認といった微妙なニュアンスを含んだ判断を伝達しようとする場合、励ます時に誇張した身振りをしたり、肩をたたいたりするといった言語表現を強調する場合等である。こうした非言語行動は、受け側に一時的な感情状態、対人的評価、話し手の性格等について推論を引き起こす。一方、毛づくろい、身体を掻くしぐさ、手をこすり合わせるといったセルフ・タッチが頻繁に行われると、不安や敵意の増大等があるかもしれないことを示唆。逆に座ってる時身体をゆすったり、足を頻繁に動かしたりすると、リラックスしていると示唆。また話しかけているときに身体動作やジェスチャが減少し 、声の調子が上ずったりすると欺瞞の指標となるという。<br />
これに対して、相互作用の調整は、インタラクションの形式や構造面に関わるものであり、焦点のはっきりしたインタラクションと、そうでもないものに大別される。焦点のはっきりしたインタラクションは、インタラクションの参加者たちがお互いに特別の関心を払い、同じ状況に居合わせた他の人を除外して、インタラクションを遂行する対面的な関わりを指す。一方焦点のはっきりしないインタラクションは、待合室に別々に座っている人達、街を歩いている人達といった、1つの場を共有しているが互いに直接話し合うことのないような状況である。焦点のはっきりしたインタラクションでは、参加者たちの位置と体の向きを中心として形成される<strong>F陣形</strong>や<strong>ターンテーキング</strong>といった動的な特徴によってインタラクションが特徴づけられる。その逆では、通りすがりの出会いにおいて相手とぶつからないような歩行の軌道調整や、視線パターンによる相手の確認、その後のインタラクションに対する意思表示が行われる。<br />
Kendon,A. : The F-Formation System : Spatial-Orientational Relations  in Face to Face Interaction, Man Environment Systems, Vol.6, pp291-296, 1976.</p>
<p>F陣形には<strong>L字型</strong>（2者の身体方向が直交するような身体配置）、<strong>対面型</strong>（2者が対面するような身体配置）、<strong>並列型</strong>（2者が並んで同じ方向に身体を向けた身体配置）等があるらしい。</p>
]]></content:encoded>
							<wfw:commentRss>http://new.shirai.la/iwadate/?feed=rss2&#038;p=55</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
		<item>
		<title>進捗11/6-/13</title>
		<link>http://new.shirai.la/iwadate/?p=34</link>
				<comments>http://new.shirai.la/iwadate/?p=34#respond</comments>
				<pubDate>Tue, 13 Nov 2012 15:00:01 +0000</pubDate>
		<dc:creator><![CDATA[iwadate]]></dc:creator>
				<category><![CDATA[研究室]]></category>

		<guid isPermaLink="false">http://new.shirai.la/iwadate/?p=34</guid>
				<description><![CDATA[・DCEXPOの整理 ・HCGシンポジウムに使う発表パワポ作り ・修論のために今 &#8230; <a href="https://new.shirai.la/iwadate/?p=34">続きを読む <span class="meta-nav">&#8594;</span></a>]]></description>
								<content:encoded><![CDATA[<h3>・DCEXPOの整理<br />
・HCGシンポジウムに使う発表パワポ作り<br />
・修論のために今までの事をTeXにまとめる<br />
・ブログ整備<br />
・出張準備</h3>
<p>&nbsp;</p>
<h2><strong>DCEXPOの整理</strong></h2>
<p><strong>写真整理</strong><br />
一眼で撮っていたブースの様子やIVRC表彰式の写真はFacebook上で研究室メンバーのみに公開中。</p>
<p><a href="https://new.shirai.la/iwadate/files/2012/11/DSC_0488.jpg"><img src="http://new.shirai.la/iwadate/files/2012/11/DSC_0488-300x198.jpg" alt="" width="300" height="198" class="aligncenter" /></a></p>
<p><strong>展示会後考察</strong><br />
Scritterに関して、「美術館の展示で、手元解説端末に同期して絵の上に解説が見えると面白い」「イベント時に運営情報（タイムスケジュール等）を見えない側に表示するのに良い」「漫画の背景を眼鏡で切り替える」「家の窓にScritterで防犯対策」といった意見をいただいた。最初にある3つは想定できうる使い方であるが、最後の家の窓にScritterで防犯対策という使い方が今回新しく出た利用法となる。しかしこの意見をいただいたのが自分ではないので詳細は不明なのが残念である。「裸眼では2D、眼鏡をかけると3D」がウリの2x3Dは、事例の説明がしやすく、利点も明らかなためとても盛況であった。驚いた表情がよく見られ、小さな子供からの「すごい！面白い！」評価もいただけた。<br />
UbiCoodeに関しては、「（イベント会場での用途として）フィルタを持っている人だけが広告の裏に見えるクイズに答えられて正解すると待ち受け画像がもらえる」といった事例での食い付きが良かったと感じた。ただ、リアプロがとても明るかったため、カメラ性能の問題でコード認識に多少難が出た場面もみられた。<br />
また瞬刊少年○○に関して、「面白かった。これが携帯アプリになったら絶対落とすのに。」といった意見もいただけた。おそらく漫画カメラのようなということなのであろうか。</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2><strong>HCGシンポジウムに使う発表パワポ作り</strong></h2>
<h3><strong>構成</strong></h3>
<p>・はじめに<br />
・関連する従来の手法<br />
・関連する従来の手法の難点<br />
・UbiCodeとは（紹介動画+1）<br />
・UbiCodeシステム構成<br />
・RFID，UbiCode手法比較実験<br />
・実験システム全体構成<br />
・RFIDを用いた簡易インタラクションシステム<br />
・ResBe<br />
・実験手順<br />
・質問内容<br />
・ResBeによる体験空間評価<br />
・実験後考察×2<br />
・まとめ</p>
<p>発表時間20分質疑応答5分<br />
残り体験動画の収録が必須。新しいScritterで収録したいところ。</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2><strong>修論のために今までの事をTEXにまとめる</strong></h2>
<p>HCGの件をまとめつつ収納中</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2><strong>ブログ整備</strong></h2>
<p>自身のブログサイトの立ち上げ、Amazonアソシエイトの導入、デザイン等<br />
せっかくだから気まぐれでアドウェイズの広告入れてみようかなとかアフィリエイトサイトにでもしてアマゾンリンク張って自分の足しにできるかなーとか思ったけど抜け道が簡単には見つからず中止。プラグインいじれるようにして欲しいっす。</p>
<iframe src="https://rcm-jp.amazon.co.jp/e/cm?t=jellyunion-22&o=9&p=8&l=as1&asins=B008CUYVPK&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2><strong>出張準備</strong></h2>
<p>資金調達、書類の作成等引き続き準備する</p>
<p>&nbsp;</p>
<p><strong>残りタスク</strong></p>
<p>・DCEXPO ResBeデータの整理（次年度のために誰かに教えるべきか否か）<br />
・UbiCode体験動画の収録<br />
・修論のために今までの事をTeXにまとめるつづき<br />
・出張準備<br />
・（鼻風邪から体調を整える）</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://new.shirai.la/iwadate/?feed=rss2&#038;p=34</wfw:commentRss>
		<slash:comments>0</slash:comments>
							</item>
	</channel>
</rss>
